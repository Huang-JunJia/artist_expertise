{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "from PIL import Image\n",
    "from vgg import *\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "#from math import \n",
    "import time\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "id_img_dict = pkl.load(open('id_img3.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_image(_id, data):\n",
    "\n",
    "    url, artist = data\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    count = 0\n",
    "    while response.status_code != 200:\n",
    "        if count > 25: return _id, None\n",
    "        time.sleep(1.0)\n",
    "        response = requests.get(url)\n",
    "        count += 1\n",
    "\n",
    "    try:\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "    except OSError:\n",
    "        return _id, None\n",
    "    \n",
    "    if img.mode == 'RGBA':\n",
    "        tmp = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "        tmp.paste(img, mask=img.split()[3]) # 3 is the alpha channel\n",
    "        img = tmp\n",
    "\n",
    "\n",
    "    \n",
    "    width, height = img.size\n",
    "    half_width, half_height = int(width/2), int(height/2)\n",
    "    offset = min(half_width, half_height)\n",
    "    \n",
    "    sq_im = img.crop((half_width-offset, half_height-offset, half_width+offset, half_height+offset))\n",
    "    #q_im.thumbnail((224, 224))\n",
    "\n",
    "\n",
    "    #convert image\n",
    "    sq_im = sq_im.resize((224, 224), Image.BICUBIC)\n",
    "        \n",
    "        \n",
    "    im = np.array(sq_im, dtype='float32')\n",
    "    try: \n",
    "        im = im.reshape(-1,224,224,3)\n",
    "    except ValueError:\n",
    "        return _id, None\n",
    "    \n",
    "    return _id, im, artist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "checkpoint_file = './vgg_16.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "id_feature_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_tensor = tf.placeholder(tf.float32, shape=(None,224,224,3), name='input_image')\n",
    "scaled_input_tensor = tf.scalar_mul((1.0/255), input_tensor)\n",
    "scaled_input_tensor = tf.subtract(scaled_input_tensor, 0.5)\n",
    "scaled_input_tensor = tf.multiply(scaled_input_tensor, 2.0)\n",
    "\n",
    "arg_scope = vgg_arg_scope()\n",
    "with slim.arg_scope(arg_scope):\n",
    "    _, end_points = vgg_16(scaled_input_tensor, is_training=False)\n",
    "    \n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, checkpoint_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "id_img_list = [x for x in id_img_list if x[0] not in id_feature_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "start = 0; batch_size = 64; end = start+batch_size\n",
    "\n",
    "pool = Pool(processes=6)\n",
    "id_imgs = id_img_list[start:end]\n",
    "while id_imgs != []:\n",
    "    \n",
    "    images = pool.starmap(get_image, id_imgs)     \n",
    "    images = [image for image in images if image[1] is not None]\n",
    "    \n",
    "    ids = [im[0] for im in images]\n",
    "    im = np.squeeze([im[1] for im in images]) #I'm removing all None types.\n",
    "    im = np.reshape(im, (-1, 224, 224, 3))\n",
    "    artists = [im[2] for im in images]\n",
    "\n",
    "    features = np.squeeze(sess.run(end_points['vgg_16/fc7'], feed_dict={input_tensor: im}))\n",
    "\n",
    "    start += batch_size; end+= batch_size\n",
    "    for id_, feats, artist in zip(ids, features, artists):\n",
    "        id_feature_dict[id_] = (feats, artist)\n",
    "    id_imgs = id_img_list[start:end]\n",
    "pool.close() \n",
    "pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47026"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(id_feature_dict, open('id_feature_dict_with_artist3.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
